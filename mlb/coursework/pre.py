import json
from pathlib import Path
import numpy as np
import pandas as pd
import os
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

import tensorflow as tf

import matplotlib.pyplot as plt

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB  # å¦‚éœ€æœ´ç´ è´å¶æ–¯ï¼Œå–æ¶ˆæ³¨é‡Š
from sklearn.metrics import accuracy_score

from sklearn.model_selection import train_test_split

# ========= å›ºå®šè·¯å¾„ï¼ˆåŒç›®å½•ï¼‰=========
DIR   = os.path.abspath(os.curdir) + "\\Dataset"
TRAIN_IN  = os.path.join(DIR,'diabetic_data_training.csv')          # åŸå§‹è®­ç»ƒæ•°æ®
TRAIN_OUT = os.path.join(DIR,'diabetic_data_preprocessed.csv')      # é¢„å¤„ç†åè®­ç»ƒæ•°æ®
TEST_IN = os.path.join(DIR,'diabetic_data_test.csv')                # åŸå§‹æµ‹è¯•æ•°æ®
TEST_OUT = os.path.join(DIR,'diabetic_data_test_preprocessed.csv')  # é¢„å¤„ç†åæµ‹è¯•æ•°æ®
NPZ_OUT = os.path.join(DIR,'diabetes_preprocessed.npz')          # X / y, ä»…ä½œé¢„å¤„ç†åçš„è®­ç»ƒæ•°æ®
# ===================================


def preprocess(df):
    # å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†

    ### è¯¥éƒ¨åˆ†æœ‰å¾…è¿›ä¸€æ­¥è°ƒæ•´ ###

    # æ•°æ®ä¸­çš„é—®å·æ›¿æ¢ä¸ºNaN
    df.replace("?", np.nan, inplace=True)
    
    # å»é™¤æœªçŸ¥æ€§åˆ«æ•°æ®
    df = df[df["gender"] != "Unknown/Invalid"].copy()
    
    # å»é™¤æ— å…³æ•°æ®ï¼ˆç—…äººIDç­‰ï¼‰å’Œä¸¥é‡ç¼ºå¤±æ•°æ®
    df.drop(columns=["weight", "medical_specialty", "payer_code", "encounter_id", "patient_nbr"], inplace=True)
    
    # å¡«è¡¥å°‘é‡ç¼ºå¤±çš„æ•°æ®
    df["race"].fillna("Unknown", inplace=True)
    # df["diag_1"].fillna("Unknown", inplace=True)
    # df["diag_2"].fillna("Unknown", inplace=True)
    df["diag_3"].fillna("Unknown", inplace=True)


    ###
    # df.drop(columns=["acetohexamide", "troglitazone", "examide", "citoglipton", 
    #                  "glimepiride-pioglitazone", "metformin-rosiglitazone", "metformin-pioglitazone"], inplace=True)

    # å¯¹readmittedï¼ˆç›®æ ‡æ ‡ç­¾ï¼‰è¿›è¡Œä¸‰åˆ†ç±»
    if "readmitted" in df.columns:
        df["readmitted"] = df["readmitted"].map({"NO": 0, ">30": 1, "<30": 2}).astype(np.int64)

    return df


def main():
    category_cols = ["race", "gender", "age", "weight", "admission_type_id", "discharge_disposition_id", 
                    "admission_source_id", "payer_code", "medical_specialty", "diag_1", "diag_2", "diag_3", 
                    "max_glu_serum", "A1Cresult", "metformin", "repaglinide", "nateglinide", "chlorpropamide", 
                    "glimepiride", "acetohexamide", "glipizide", "glyburide", "tolbutamide", "pioglitazone", "rosiglitazone", 
                    "acarbose", "miglitol", "troglitazone", "tolazamide", "examide", "citoglipton", "insulin", "glyburide-metformin", 
                    "glipizide-metformin", "glimepiride-pioglitazone", "metformin-rosiglitazone", "metformin-pioglitazone", "change", 
                    "diabetesMed"]
    
    # è¯»å–åŸå§‹è®­ç»ƒæ•°æ®
    df = pd.read_csv(TRAIN_IN)

    # åŸºæœ¬é¢„å¤„ç†
    df = preprocess(df)


    # one hot code the category type
    all_cols = df.columns
    category_cols = [col for col in all_cols if col in category_cols]

    cat_cols = category_cols
    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)
    print("\nâœ… è®­ç»ƒæ•°æ®One-Hotç¼–ç å®Œæˆ")
    df.to_csv(TRAIN_OUT, index=False)

    # æ‹†åˆ† X / y
    y = df["readmitted"].to_numpy(dtype=np.int64)
    X = df.drop(columns=["readmitted"]).to_numpy(dtype=np.float32)

    # ä¿å­˜ä»…é¢„å¤„ç†åè®­ç»ƒæ•°æ®
    np.savez(NPZ_OUT, X=X, y=y)
    
    # è¯»å–å¹¶é¢„å¤„ç†æµ‹è¯•é›†
    df_test = pd.read_csv(TEST_IN)
    df_test = preprocess(df_test)

    df_test = pd.get_dummies(df_test, columns=cat_cols, drop_first=True)
    print("\nâœ… è®­ç»ƒæ•°æ®One-Hotç¼–ç å®Œæˆ")
    # ç¡®ä¿æµ‹è¯•é›†ä¸è®­ç»ƒé›†åˆ—å¯¹é½
    df_test = df_test.reindex(columns=df.columns, fill_value=0)
    df_test.to_csv(TEST_OUT, index=False)
    # å®Œæˆæç¤º
    print("\nâœ… è®­ç»ƒé›†ã€æµ‹è¯•é›†é¢„å¤„ç†å®Œæˆ")

if __name__ == "__main__":
    main()

DIR   = os.path.abspath(os.curdir) + "\\Dataset"
CSV_IN = os.path.join(DIR,'diabetic_data_preprocessed.csv') 
NPZ_OUT = os.path.join(DIR,'diabetes_with_pca.npz')

def main():
    df = pd.read_csv(CSV_IN) # è¯»å–éœ€è¦åšé™ç»´çš„è®­ç»ƒæ•°æ®

    # æ‰‹åŠ¨æŒ‡å®šåˆ†ç±»ç‰¹å¾
    category_cols = ["race", "gender", "age", "weight", "admission_type_id", "discharge_disposition_id", 
                    "admission_source_id", "payer_code", "medical_specialty", "diag_1", "diag_2", "diag_3", 
                    "max_glu_serum", "A1Cresult", "metformin", "repaglinide", "nateglinide", "chlorpropamide", 
                    "glimepiride", "acetohexamide", "glipizide", "glyburide", "tolbutamide", "pioglitazone", "rosiglitazone", 
                    "acarbose", "miglitol", "troglitazone", "tolazamide", "examide", "citoglipton", "insulin", "glyburide-metformin", 
                    "glipizide-metformin", "glimepiride-pioglitazone", "metformin-rosiglitazone", "metformin-pioglitazone", "change", 
                    "diabetesMed", "readmitted"]

    # è®¡ç®—æ•°å€¼ç‰¹å¾é›†åˆå’ŒçœŸæ­£çš„åˆ†ç±»ç‰¹å¾é›†åˆ
    # åˆ†ç±»ç‰¹å¾é›†åˆéœ€è¦å†æ¬¡è®¡ç®—ï¼Œå› ä¸ºæ­¤æ—¶è¾“å…¥æ•°æ®æ˜¯é¢„å¤„ç†è¿‡çš„ï¼Œå¯èƒ½å·²ç»å¤±å»äº†éƒ¨åˆ†åˆ†ç±»ç‰¹å¾
    all_cols = df.columns
    num_cols = [col for col in all_cols if col not in category_cols]

    # æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾
    scaler = StandardScaler()
    X_num_scaled = scaler.fit_transform(df[num_cols])

    # PCA é™å™ª åˆæ­¥æµ‹è¯•åœ¨ä¿æŒ87%~93%æ–¹å·®æ—¶æ•ˆæœæœ€å¥½
    pca = PCA(n_components=0.93, random_state=42)
    X_final = pca.inverse_transform(pca.fit_transform(X_num_scaled))
    
    y = df["readmitted"].to_numpy(dtype=np.int64)

    # ç»“æœä¿å­˜ä¸º npz æ–‡ä»¶ï¼š
    np.savez(NPZ_OUT, X=X_final, y = y)
    print("âœ… PCA é™ç»´å®Œæˆ")

if __name__ == "__main__":
    main()

# ---------- å›ºå®šæ–‡ä»¶å ----------
TRAIN_NPZ = os.path.join(DIR,'diabetes_with_pca.npz') # é¢„å¤„ç†å¹¶PCAå¤„ç†çš„è®­ç»ƒæ•°æ®
TEST_CSV = os.path.join(DIR,'diabetic_data_test_preprocessed.csv') # é¢„å¤„ç†è¿‡çš„æµ‹è¯•æ•°æ®
# ---------------------------------

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import time

def print_progress(current, total, start_time, prefix=""):
    """æ‰“å°è¿›åº¦æ¡å’Œé¢„è®¡å‰©ä½™æ—¶é—´"""
    elapsed = time.time() - start_time
    progress = current / total
    remaining = elapsed / progress * (1 - progress) if progress > 0 else 0
    
    bar_length = 30
    filled_length = int(bar_length * progress)
    bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
    
    print(f"\r{prefix}[{bar}] {current}/{total} | ç”¨æ—¶: {elapsed:.1f}s | å‰©ä½™: {remaining:.1f}s", end="")
    if current == total:
        print()

def main():
    # ---------------- 1. è¯»å–æ•°æ® ----------------
    print("="*50)
    print("å¼€å§‹åŠ è½½æ•°æ®é›†...")
    data = np.load(TRAIN_NPZ)
    X_train, y_train = data["X"].astype(np.float32), data["y"].astype(np.int64)
    
    df_test = pd.read_csv(TEST_CSV)
    if "readmitted" not in df_test.columns:
        raise ValueError("æµ‹è¯•é›†ç¼ºå°‘ 'readmitted' æ ‡ç­¾åˆ—ï¼Œæ— æ³•è¯„ä¼°å‡†ç¡®ç‡")
    
    y_test = df_test["readmitted"].to_numpy(dtype=np.int64)
    X_test = df_test.drop(columns=["readmitted"]).to_numpy(dtype=np.float32)
    
    if X_test.shape[1] != X_train.shape[1]:
        raise ValueError(f"ç‰¹å¾ç»´åº¦ä¸ä¸€è‡´ï¼štrain {X_train.shape[1]}, test {X_test.shape[1]}")
    print("âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
    
    # ---------------- 2. æ•°æ®æ ‡å‡†åŒ– ----------------
    print("\næ­£åœ¨è¿›è¡Œæ•°æ®æ ‡å‡†åŒ–...")
    scaler = StandardScaler()
    X_train_sc = scaler.fit_transform(X_train)
    X_test_sc = scaler.transform(X_test)
    print("âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ")
    
    # ---------------- 3. é€»è¾‘å›å½’è°ƒä¼˜ ----------------
    print("\n" + "="*50)
    print("å¼€å§‹é€»è¾‘å›å½’æ¨¡å‹è°ƒä¼˜")
    
    # å®šä¹‰é€»è¾‘å›å½’å‚æ•°ç½‘æ ¼
    param_grid = {
        'C': [0.001, 0.01, 0.1, 1, 10, 100],  # æ­£åˆ™åŒ–å¼ºåº¦çš„å€’æ•°
        'penalty': ['l2'],  # æ­£åˆ™åŒ–ç±»å‹
        'solver': ['lbfgs', 'sag', 'saga'],  # ä¼˜åŒ–ç®—æ³•
        'max_iter': [100, 200, 500],  # æœ€å¤§è¿­ä»£æ¬¡æ•°
        'class_weight': [None, 'balanced']  # ç±»åˆ«æƒé‡
    }
    
    # è®¡ç®—æ€»å‚æ•°ç»„åˆæ•°
    total_params = 1
    for v in param_grid.values():
        total_params *= len(v)
    
    # ä½¿ç”¨åˆ†å±‚KæŠ˜äº¤å‰éªŒè¯ï¼ˆä¿æŒç±»åˆ«åˆ†å¸ƒï¼‰
    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    
    # åˆ›å»ºé€»è¾‘å›å½’æ¨¡å‹
    lr_model = LogisticRegression(multi_class='multinomial')
    
    # ç½‘æ ¼æœç´¢
    print(f"\nå‚æ•°æœç´¢ç©ºé—´: {param_grid}")
    print(f"å¼€å§‹äº¤å‰éªŒè¯ (å…± {total_params} ç§å‚æ•°ç»„åˆ Ã— 5 æŠ˜äº¤å‰éªŒè¯)...")
    search_start = time.time()
    
    grid = GridSearchCV(
        estimator=lr_model,
        param_grid=param_grid,
        cv=cv,
        scoring='accuracy',
        n_jobs=-1,
        verbose=1  # ä½¿ç”¨sklearnå†…ç½®çš„verboseæ˜¾ç¤ºè¿›åº¦
    )
    
    # æ‰§è¡Œç½‘æ ¼æœç´¢
    grid.fit(X_train_sc, y_train)
    
    # ---------------- 4. ç»“æœè¯„ä¼° ----------------
    print("\n" + "="*50)
    print("é€»è¾‘å›å½’è°ƒä¼˜å®Œæˆ")
    print(f"æ€»è®­ç»ƒæ—¶é—´: {time.time() - search_start:.1f}ç§’")
    
    # è·å–æœ€ä½³æ¨¡å‹
    best_lr = grid.best_estimator_
    
    # åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°
    y_train_pred = best_lr.predict(X_train_sc)
    train_acc = accuracy_score(y_train, y_train_pred)
    
    # åœ¨æµ‹è¯•é›†ä¸Šçš„è¡¨ç°
    y_test_pred = best_lr.predict(X_test_sc)
    test_acc = accuracy_score(y_test, y_test_pred)
    
    print(f"\nğŸ” æœ€ä½³å‚æ•°: {grid.best_params_}")
    print(f"ğŸ† äº¤å‰éªŒè¯æœ€ä½³å‡†ç¡®ç‡: {grid.best_score_:.4f}")
    print(f"ğŸ“Š è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc:.4f}")
    print(f"ğŸ§ª æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f}")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    print("\nåˆ†ç±»æŠ¥å‘Š (æµ‹è¯•é›†):")
    print(classification_report(y_test, y_test_pred))
    
    print("\næ··æ·†çŸ©é˜µ (æµ‹è¯•é›†):")
    print(confusion_matrix(y_test, y_test_pred))
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    import joblib
    model_path = os.path.join(DIR, 'best_lr_model.pkl')
    joblib.dump(best_lr, model_path)
    print(f"\nğŸ’¾ æœ€ä½³æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

if __name__ == "__main__":
    main()