{
  "model": "Qwen/Qwen2.5-0.5B-Instruct",
  "method": "prefix",
  "qlora": false,
  "data_dir": "D:\\Buendia\\CL\\clForLLM\\peft\\data\\alpaca",
  "alpaca_full_jsonl": "D:\\Buendia\\CL\\clForLLM\\peft\\data\\alpaca\\alpaca_full.jsonl",
  "current_split_dir": "D:\\Buendia\\CL\\clForLLM\\peft\\data\\alpaca\\current_split",
  "train_size": 1000,
  "eval_size": 200,
  "max_length": 512,
  "learning_rate": 0.001,
  "optimizer": "adamw_torch",
  "trainable_params": {
    "trainable": 21504,
    "total": 494054272,
    "pct": 0.0044
  },
  "dataset_stats": {
    "train_examples": 1000,
    "eval_examples": 200,
    "avg_train_tokens": 160.75,
    "avg_eval_tokens": 139.42
  },
  "pre_eval": {
    "eval_loss": 2.1850333213806152,
    "perplexity": 8.890944806991497,
    "eval_runtime_sec": 5.775
  },
  "post_eval": {
    "eval_loss": 2.1652603149414062,
    "perplexity": 8.716870753231797,
    "eval_runtime_sec": 5.085
  },
  "train_wall_time_sec": 163.847,
  "avg_step_time_sec": 0.8192,
  "fallback_used": null,
  "trainer_metrics": {
    "train_runtime": 163.7646,
    "train_samples_per_second": 9.77,
    "train_steps_per_second": 1.221,
    "total_flos": 552975069131520.0,
    "train_loss": 2.0215573787689207,
    "epoch": 1.6
  },
  "artifacts": {
    "adapter_dir": "D:\\Buendia\\CL\\clForLLM\\peft\\runs\\alpaca_ln\\adapter",
    "loss_log_csv": "D:\\Buendia\\CL\\clForLLM\\peft\\runs\\alpaca_ln\\results\\loss_log.csv",
    "trainer_state_json": null,
    "trainer_config_json": null
  }
}