{
  "model": "Qwen/Qwen2.5-0.5B-Instruct",
  "method": "lora",
  "qlora": false,
  "data_dir": "D:\\Buendia\\CL\\clForLLM\\peft\\data\\alpaca",
  "alpaca_full_jsonl": "D:\\Buendia\\CL\\clForLLM\\peft\\data\\alpaca\\alpaca_full.jsonl",
  "current_split_dir": "D:\\Buendia\\CL\\clForLLM\\peft\\data\\alpaca\\current_split",
  "train_size": 1000,
  "eval_size": 200,
  "max_length": 512,
  "learning_rate": 0.0002,
  "optimizer": "adamw_torch",
  "trainable_params": {
    "trainable": 1081344,
    "total": 495114112,
    "pct": 0.2184
  },
  "dataset_stats": {
    "train_examples": 1000,
    "eval_examples": 200,
    "avg_train_tokens": 160.75,
    "avg_eval_tokens": 139.42
  },
  "pre_eval": {
    "eval_loss": 2.1850333213806152,
    "perplexity": 8.890944806991497,
    "eval_runtime_sec": 5.732
  },
  "post_eval": {
    "eval_loss": 1.4422385692596436,
    "perplexity": 4.230154720161684,
    "eval_runtime_sec": 6.608
  },
  "train_wall_time_sec": 205.229,
  "avg_step_time_sec": 1.0261,
  "trainer_metrics": {
    "train_runtime": 205.1402,
    "train_samples_per_second": 7.8,
    "train_steps_per_second": 0.975,
    "total_flos": 554612490136320.0,
    "train_loss": 1.4378782939910888,
    "epoch": 1.6
  },
  "artifacts": {
    "adapter_dir": "D:\\Buendia\\CL\\clForLLM\\peft\\runs\\alpaca_lora\\adapter",
    "loss_log_csv": "D:\\Buendia\\CL\\clForLLM\\peft\\runs\\alpaca_lora\\results\\loss_log.csv",
    "trainer_state_json": null,
    "trainer_config_json": null
  }
}